{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Results Analysis and Visualization\n",
                "\n",
                "This notebook analyzes model results and creates visualizations.\n",
                "\n",
                "## Contents:\n",
                "1. Load model results\n",
                "2. Forecast visualization\n",
                "3. Residual analysis\n",
                "4. Error distribution\n",
                "5. Performance by segment\n",
                "6. Business insights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "sys.path.append(str(Path.cwd().parent))\n",
                "\n",
                "from src.visualization import (\n",
                "    plot_forecast,\n",
                "    plot_residuals,\n",
                "    plot_model_comparison,\n",
                "    plot_seasonal_decomposition\n",
                ")\n",
                "\n",
                "sns.set_style(\"whitegrid\")\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load evaluation results if available\n",
                "results_path = Path.cwd().parent / \"models\" / \"evaluation_results.csv\"\n",
                "\n",
                "if results_path.exists():\n",
                "    results_df = pd.read_csv(results_path, index_col=0)\n",
                "    print(\"Model Performance Results:\")\n",
                "    print(results_df.to_string())\n",
                "else:\n",
                "    print(\"No results file found. Run the training pipeline first.\")\n",
                "    results_df = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Forecast Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Create sample forecast visualization\n",
                "# In practice, you would load actual forecasts from saved models\n",
                "\n",
                "dates = pd.date_range('2023-11-01', periods=42, freq='D')\n",
                "np.random.seed(42)\n",
                "\n",
                "# Simulated data for demonstration\n",
                "actuals = 100 + 10 * np.sin(np.arange(42) * 2 * np.pi / 7) + np.random.normal(0, 5, 42)\n",
                "forecast = actuals + np.random.normal(0, 3, 42)\n",
                "\n",
                "plot_forecast(\n",
                "    actuals=actuals,\n",
                "    forecasts=forecast,\n",
                "    dates=dates,\n",
                "    title='6-Week Forecast vs Actual'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Residual Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Residual analysis\n",
                "residuals = actuals - forecast\n",
                "\n",
                "plot_residuals(\n",
                "    residuals=residuals,\n",
                "    dates=dates,\n",
                "    title='Residual Analysis'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if results_df is not None:\n",
                "    # Plot comparison for different metrics\n",
                "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "    \n",
                "    metrics = ['mae', 'rmse', 'mape', 'smape']\n",
                "    \n",
                "    for idx, metric in enumerate(metrics):\n",
                "        ax = axes[idx // 2, idx % 2]\n",
                "        if metric in results_df.columns:\n",
                "            sorted_results = results_df.sort_values(metric)\n",
                "            ax.barh(sorted_results.index, sorted_results[metric], color='steelblue')\n",
                "            ax.set_xlabel(metric.upper())\n",
                "            ax.set_title(f'Model Comparison by {metric.upper()}')\n",
                "            ax.grid(True, alpha=0.3, axis='x')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Error Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Error distribution analysis\n",
                "errors = actuals - forecast\n",
                "percentage_errors = (errors / actuals) * 100\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Absolute errors\n",
                "axes[0].hist(errors, bins=20, edgecolor='black', alpha=0.7)\n",
                "axes[0].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
                "axes[0].set_title('Distribution of Forecast Errors')\n",
                "axes[0].set_xlabel('Error (Actual - Forecast)')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Percentage errors\n",
                "axes[1].hist(percentage_errors, bins=20, edgecolor='black', alpha=0.7, color='coral')\n",
                "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
                "axes[1].set_title('Distribution of Percentage Errors')\n",
                "axes[1].set_xlabel('Percentage Error (%)')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Mean Error: {errors.mean():.2f}\")\n",
                "print(f\"Std Error: {errors.std():.2f}\")\n",
                "print(f\"Mean Absolute Error: {np.abs(errors).mean():.2f}\")\n",
                "print(f\"Mean Percentage Error: {percentage_errors.mean():.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Performance by Time Period"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze performance by week\n",
                "df_analysis = pd.DataFrame({\n",
                "    'date': dates,\n",
                "    'actual': actuals,\n",
                "    'forecast': forecast,\n",
                "    'error': errors,\n",
                "    'abs_error': np.abs(errors)\n",
                "})\n",
                "\n",
                "df_analysis['week'] = (df_analysis.index // 7) + 1\n",
                "\n",
                "weekly_performance = df_analysis.groupby('week').agg({\n",
                "    'abs_error': 'mean',\n",
                "    'error': 'std'\n",
                "})\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "axes[0].bar(weekly_performance.index, weekly_performance['abs_error'])\n",
                "axes[0].set_title('Mean Absolute Error by Week')\n",
                "axes[0].set_xlabel('Week')\n",
                "axes[0].set_ylabel('MAE')\n",
                "axes[0].grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "axes[1].bar(weekly_performance.index, weekly_performance['error'], color='coral')\n",
                "axes[1].set_title('Error Standard Deviation by Week')\n",
                "axes[1].set_xlabel('Week')\n",
                "axes[1].set_ylabel('Std Dev')\n",
                "axes[1].grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Business Insights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate business metrics\n",
                "total_actual = actuals.sum()\n",
                "total_forecast = forecast.sum()\n",
                "bias = ((total_forecast - total_actual) / total_actual) * 100\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"BUSINESS METRICS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Total Actual Sales: ${total_actual:,.2f}\")\n",
                "print(f\"Total Forecasted Sales: ${total_forecast:,.2f}\")\n",
                "print(f\"Forecast Bias: {bias:+.2f}%\")\n",
                "print(f\"\\nAverage Daily Sales: ${actuals.mean():,.2f}\")\n",
                "print(f\"Sales Volatility (Std): ${actuals.std():,.2f}\")\n",
                "print(f\"\\nForecast Accuracy (MAPE): {np.mean(np.abs(percentage_errors)):.2f}%\")\n",
                "print(f\"Forecast Precision (Std of Errors): ${errors.std():.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Recommendations\n",
                "\n",
                "### Model Performance:\n",
                "- Best performing model should be deployed to production\n",
                "- Monitor forecast accuracy weekly\n",
                "- Retrain models monthly with new data\n",
                "\n",
                "### Business Actions:\n",
                "- Use forecasts for inventory planning\n",
                "- Adjust staffing based on predicted demand\n",
                "- Plan promotions during low-demand periods\n",
                "- Set safety stock levels based on forecast uncertainty\n",
                "\n",
                "### Model Improvements:\n",
                "- Incorporate external factors (weather, events)\n",
                "- Add store-specific models for better accuracy\n",
                "- Implement online learning for concept drift\n",
                "- Develop confidence intervals for risk management"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}