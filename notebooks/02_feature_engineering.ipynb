{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Exploration\n",
    "\n",
    "This notebook explores feature engineering techniques for time series forecasting.\n",
    "\n",
    "## Objectives\n",
    "1. Create temporal features\n",
    "2. Generate lag features\n",
    "3. Build rolling window statistics\n",
    "4. Add holiday indicators\n",
    "5. Analyze feature importance\n",
    "6. Select optimal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from src.data_loader import load_sales_data\n",
    "from src.feature_engineering import FeatureEngineer\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and aggregate data\n",
    "df = load_sales_data(Path.cwd().parent / \"data\" / \"raw\" / \"sales_data.parquet\")\n",
    "df_agg = df.groupby(['store_id', 'date'])['sales'].sum().reset_index()\n",
    "df_promo = df.groupby(['store_id', 'date'])['is_promo'].max().reset_index()\n",
    "df_agg = df_agg.merge(df_promo, on=['store_id', 'date'])\n",
    "\n",
    "print(f\"Data shape: {df_agg.shape}\")\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features\n",
    "engineer = FeatureEngineer(df_agg, date_column='date')\n",
    "df_temporal = engineer.add_temporal_features()\n",
    "\n",
    "print(\"Temporal features created:\")\n",
    "temporal_cols = [col for col in df_temporal.columns if col not in df_agg.columns]\n",
    "print(temporal_cols)\n",
    "\n",
    "df_temporal[['date'] + temporal_cols[:5]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features\n",
    "df_lags = engineer.add_lag_features(\n",
    "    target_column='sales',\n",
    "    lags=[1, 7, 14, 28],\n",
    "    group_columns=['store_id']\n",
    ")\n",
    "\n",
    "lag_cols = [col for col in df_lags.columns if 'lag' in col]\n",
    "print(f\"\\nLag features: {lag_cols}\")\n",
    "\n",
    "# Visualize lag correlations\n",
    "store_1 = df_lags[df_lags['store_id'] == 1].dropna()\n",
    "corr_matrix = store_1[['sales'] + lag_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Lag Feature Correlations (Store 1)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rolling Window Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling features\n",
    "df_rolling = engineer.add_rolling_features(\n",
    "    target_column='sales',\n",
    "    windows=[7, 14, 28],\n",
    "    stats=['mean', 'std'],\n",
    "    group_columns=['store_id']\n",
    ")\n",
    "\n",
    "rolling_cols = [col for col in df_rolling.columns if 'rolling' in col]\n",
    "print(f\"Rolling features: {rolling_cols}\")\n",
    "\n",
    "# Plot rolling statistics\n",
    "store_1_data = df_rolling[df_rolling['store_id'] == 1].set_index('date')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(store_1_data.index, store_1_data['sales'], label='Actual', alpha=0.5)\n",
    "axes[0].plot(store_1_data.index, store_1_data['sales_rolling_7_mean'], label='7-day MA')\n",
    "axes[0].plot(store_1_data.index, store_1_data['sales_rolling_28_mean'], label='28-day MA')\n",
    "axes[0].set_title('Sales with Rolling Means')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(store_1_data.index, store_1_data['sales_rolling_7_std'], label='7-day Std')\n",
    "axes[1].plot(store_1_data.index, store_1_data['sales_rolling_28_std'], label='28-day Std')\n",
    "axes[1].set_title('Rolling Standard Deviation')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Holiday Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create holiday features\n",
    "df_holidays = engineer.add_holiday_features()\n",
    "\n",
    "holiday_cols = [col for col in df_holidays.columns if 'holiday' in col]\n",
    "print(f\"Holiday features: {holiday_cols}\")\n",
    "\n",
    "# Analyze holiday impact\n",
    "holiday_impact = df_holidays.groupby('is_holiday')['sales'].agg(['mean', 'median', 'std'])\n",
    "holiday_impact.index = ['Non-Holiday', 'Holiday']\n",
    "print(\"\\nHoliday Impact:\")\n",
    "print(holiday_impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete feature set\n",
    "df_features = engineer.create_all_features(\n",
    "    target_column='sales',\n",
    "    group_columns=['store_id']\n",
    ")\n",
    "\n",
    "print(f\"Total features: {len(df_features.columns)}\")\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"  - Temporal: {len([c for c in df_features.columns if any(x in c for x in ['year', 'month', 'day', 'week'])])}\")\n",
    "print(f\"  - Lag: {len([c for c in df_features.columns if 'lag' in c])}\")\n",
    "print(f\"  - Rolling: {len([c for c in df_features.columns if 'rolling' in c])}\")\n",
    "print(f\"  - Holiday: {len([c for c in df_features.columns if 'holiday' in c])}\")\n",
    "print(f\"  - Promotion: {len([c for c in df_features.columns if 'promo' in c])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (Quick ML Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Prepare data for one store\n",
    "store_data = df_features[df_features['store_id'] == 1].dropna()\n",
    "feature_cols = [col for col in store_data.columns \n",
    "                if col not in ['date', 'store_id', 'sales']]\n",
    "\n",
    "X = store_data[feature_cols]\n",
    "y = store_data['sales']\n",
    "\n",
    "# Train quick RF model\n",
    "rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_20 = importance_df.head(20)\n",
    "plt.barh(range(len(top_20)), top_20['importance'])\n",
    "plt.yticks(range(len(top_20)), top_20['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "### Feature Engineering Insights:\n",
    "\n",
    "1. **Lag Features**: Strong correlation with recent lags (1, 7 days)\n",
    "2. **Rolling Features**: Capture trend and volatility effectively\n",
    "3. **Holiday Features**: Significant impact on sales\n",
    "4. **Temporal Features**: Day of week shows strong patterns\n",
    "5. **Feature Importance**: Lag features typically most important\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "- Focus on lag features (1, 7, 14, 28 days)\n",
    "- Include rolling means and standard deviations\n",
    "- Add holiday indicators and proximity features\n",
    "- Use cyclical encoding for temporal features\n",
    "- Consider interaction features for promotions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
